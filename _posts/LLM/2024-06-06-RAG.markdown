---
title: "RAG"
layout: post
date: 2024-06-06 00:43
image: /assets/images/markdown.jpg
headerImage: ture
tag:
- markdown
- components
- extra
hidden: false
category: LLM
author: Zhenshuai Yin
description: 记录一下在LLM中RAG的作用和实现方法
---

参考:[用通俗易懂的方式讲解：一文讲清大模型 RAG 技术全流程_rag技术初期rag-CSDN博客](https://blog.csdn.net/2301_78285120/article/details/135494908)

[【原创】一文读懂RAG的来源、发展和前沿-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2400670)

[RAG概述（一）：RAG架构的演进_module rag native rag-CSDN博客](https://blog.csdn.net/hugo_lei/article/details/138815488)

# 大模型中的RAG技术

## 为什么要使用RAG

目前大语言模型LLM存在幻觉问题(生成的内容与提供的源内容不符或没有意义, 幻觉的产生通常是由于模型在训练过程中学习到的信息是不完整的, 或者模型在尝试生成看似合理但实际上并非基于真实信息的内容时过度自信), 不够专业的回答(大模型在通用领域训练时缺少某一专业性高的垂直领域知识)和生成不具有时效性的问题(大模型只能记录当前数据中已有的世界知识, 对于新增长的世界知识, 模型可能生成不专业或毫无意义的内容)

针对如何解决幻觉问题, 以下是几种常见的解决方案:

​	预定义的输入模板

​	推理(增强其推理能力)

​	反馈(结合人类反馈和强化学习来微调模型(RLHF))

​	模型配置(修改其温度, top-p等)

​	迭代查询(迭代多次查询最佳答案, 当用户提出一个问题, 大语言模型会在知识库中查询类似的问题, 然后用所有问题查询向量数据库, 总结答案并检查答案看起来是否合理, 如果没有合理答案则重复这些步骤, 直到出现为止)

​	检索增强生成(使用外部数据源的信息辅助文本生成. 将检索与生成结合的实践). 把检索的得到的信息与用户源信息合并为输入, 让大语言模型从包含外部信息的提示中学习知识(in-context Learning)

为了让大模型的回答更准确, 专业和具有时效性, 检索增强生成技术(RAG)被提出. 其无需算力和对数据私有性和安全性的保障使其备受关注.

## RAG的特点

RAG允许LLM在无需重新训练的情况下利用额外的数据资源来提高回答的质量(具体实现方式为, 将检索到的相关知识拼接到输入中, 以Prompt Tuning的方式提高其回答质量)

RAG模型基于数据(通常为私有数据或专业数据)构建知识存储库, 并且存储库可以不断更新(并且非常方便), 可以为生成式AI提供及时的上下文答案.

![img](https://tuchuang-yzs.oss-cn-beijing.aliyuncs.com/b73c46a1e7965480af469505425201b9.png)

## RAG的核心部件

### 向量数据库(Vector Database)

向量数据库是一种专门设计用来高效存储和检索向量数据的数据库系统. 数据经常以高维向量的形式存在, 如文本, 图片或其他类型的数据经过嵌入模型转换成向量. 这些向量代表了原始数据的特征和语义信息, 可以用于各种相似性搜索和数据分析人物. 向量数据库提供高效率的存储和检索算法. 检索增强生成模型的一个关键步骤就是从大规模数据集中检索相关信息, 这些信息随后用于辅助生成模型产生回答. 向量数据库能够快速检索到与查询向量最相似的数据向量.

### 查询检索(Retriever)

在检索增强生成过程中, 检索器可以从一个大规模的文档集合或知识库中检索出于给定查询最相关的信息, 这个过程是通过比较查询的表示(通常是一个向量)和文档集合中每个文档的表示来完成的.

![img](https://tuchuang-yzs.oss-cn-beijing.aliyuncs.com/05e06060d1f2f20127752b3d1c86a842.png)

### 重新排序(Re-ranker)

我们可以在许多文本文档中执行语义搜索, 但由于LLM对于传递token量有限制, 我们需要对文档质量进行排序, 然后返回top-k个文档用于下一步检索生成. 在重排器中, 给定查询和文档对, 输出相似性得分, 我们使用这个分数进行排序.

### 生成回答(Generator)

在整个检索增强生成系统中，生成器是负责将检索到的信息生成最终文本输出的组件，它利用这些检索到的信息来构建回答或完成特定的文本生成任务。生成器将检索到的多个文档或信息片段综合考虑，融合它们的内容来构建一个连贯、逻辑一致的输出。这个过程涉及到语言生成的各个方面，包括词汇选择、语法结构和内容连贯性等。 因为检索增强生成不仅用于事实推理，还可以被用于生成代码、图像等，因此面对不同下游任务，生成器模型已经衍生出多种变体。Transformer模型经常应用于文本生成任务；VisualGPT常用于从图像生成文本描述；Stable Diffusion主要用于根据文本提示生成图像；Codex则专注于从文本描述生成代码。

![img](https://developer.qcloudimg.com/http-save/yehe-1599485/b94f700e6d03c2d732ef9900fbc6f51f.png)

## RAG前沿

### RAG+Knowledge Graph

首先, 使用大语言模型从用户问题中提取关键实体. 然后基于这些实体来检索子图, 最后大模型用获得的上下文(实体的邻接矩阵信息)生成答案

![img](https://tuchuang-yzs.oss-cn-beijing.aliyuncs.com/7ce8ee08eb8c51df3ea9ee0cffcb8840.png)

### RAG+Tree

文章引入了递归嵌入、聚类和总结文本块的新颖方法，从下到上构建具有不同摘要级别的树。最开始，将检索语料库分割成长度为100的短连续文本。然后用SBERT进行句子嵌入。为了对相似的文本块进行分组，可以采用聚类算法。聚类后，语言模型用于总结分组的文本。然后将这些总结的文本重新嵌入。这样的过程不断进行，直到不能进一步聚类。于是我们有了原始文档的结构化、多层树的表示。

![img](https://developer.qcloudimg.com/http-save/yehe-1599485/119d4b43f526438386227e37272690b0.png)

### Modular RAG

模块化RAG结构与传统的朴素RAG框架不同，提供了更大的灵活性和适应性。它整合了各种方法来增强功能模块，例如加入搜索模块进行相似性检索，并在检索器中应用微调方法。重构的RAG模块和迭代方法已被开发出来以解决特定问题。

模块化RAG范式在RAG领域越来越成为常态，允许通过多个模块进行序列化流水线或端到端训练。





























